import os
import subprocess
import urllib.parse
import urllib.request

configfile: "config.yaml"

#rule localrules: all, clean

rule all:
    input:
#        "db/uniparc_active.fasta.gz",
        "hmm_profiles/PF01397.hmm",
        "hmm_profiles/PF03936.hmm",
	    "uniparc_chunks",
        "hmm_combined.out",
	    "upi.txt",
        "output.txt"
       # "hmm_results"

rule clean:
    shell:
        """
        rm -rf hmm_results logs
        """
    
#rule download_uniparc:
#    output:
#        "db/uniparc_active.fasta.gz"
#    log:
#        "logs/download_uniparc.log"
#    params:
#        memory="2"
#    threads:
#        1
#    shell:
#        """
#        wget --directory-prefix db "https://ftp.expasy.org/databases/uniprot/current_release/uniparc/uniparc_active.fasta.gz" &> {log}
#        """

rule download_hmmprofiles:
    output:
        terpene_synth="hmm_profiles/PF01397.hmm", # Terpene_synth (PF01397)
        terpene_synth_C="hmm_profiles/PF03936.hmm" # Family: Terpene_synth_C (PF03936)
    log:
        "logs/download_hmmprofiles.log"
    params:
        memory="2"
    threads:
        1
    shell:
        """
        wget -O hmm_profiles/PF01397.hmm "http://pfam.xfam.org/family/PF01397/hmm" &> {log}
        wget -O hmm_profiles/PF03936.hmm "http://pfam.xfam.org/family/PF03936/hmm" &>> {log}
        """

# split the database into smaller chunks so it an be searched with hmmsearch - max is 100K?
checkpoint split_uniparc:
    input:
        uniparc="uniparc_active.fasta.gz"
    output:
        directory("uniparc_chunks")
    log:
        "logs/uniparc_split.log"
    params:
        memory="2" #TODO: change the value?
    threads:
        2
    shell:
        """
        seqkit split {input.uniparc} -s 10000 --two-pass -O "uniparc_chunks" --threads 2 2> {log}
        """

# run hmmsearch on the chunks - returns sequences IDs matcching the provided hmm
rule hmmsearch:
    input:
        terpene_synth="hmm_profiles/PF01397.hmm", # Terpene_synth (PF01397)
        terpene_synth_C="hmm_profiles/PF03936.hmm", # Family: Terpene_synth_C (PF03936)
        uniparc_chunk="uniparc_chunks/uniparc_active.part_{index}.fasta"
    output:
        hmm="hmm_results/hmm_{index}.tsv"
    params:
        memory="10" #TODO: change the value?
    threads:
        16
    shell:
        """
        hmmsearch --noali --tblout {output.hmm} -E {config[e_value_threshold]} --cpu {threads} {input.terpene_synth} {input.uniparc_chunk} 
        """

def aggregate_input(wildcards):
    checkpoints_output = checkpoints.split_uniparc.get(**wildcards).output[0]
    indeces = glob_wildcards(os.path.join(checkpoints_output, "uniparc_active.part_{index}.fasta")).index
    completed = expand(os.path.join("hmm_results", "hmm_{index}.tsv"),index=indeces)
    return completed    

#return expand("hmm_results/hmm_{index}.tsv", index=glob_wildcards(os.path.join(checkpoints_output,"uniparc_active.part_{index}.fasta")).index)


rule combine_hmm:
    input:
        aggregate_input
    output:
        "hmm_combined.out"
    log:
        "logs/combine_hmm.log"
    params:
        memory="1"
    threads:
        1
    shell:
        """
        cat {input} | grep -v '#'> {output}
        """
rule get_UPIs:
    input:
        upi_file="hmm_combined.out"
    output:
        upi_list="upi.txt"
    log:
        "logs/get_UPIs.out"
    params:
        memory="1"
    threads:
        1
    shell:
        """
        cut -d ' ' -f 1 {input.upi_file} > {output.upi_list} 
        """
checkpoint split_UPIs:
    input:
        upi_list="upi.txt"
    output:
        directory("UPIs")
    log:
        "logs/split_UPIs"
    params:
        memory="1"
    threads:
        1
    shell:
        """
        mkdir -p {output}
        split -d -l 10 {input} {output}/upi_
        """
        
rule get_uniprot_data:
    input:
        upi_file="UPIs/upi_{index}"
    output:
        uniprot_data="seq_{index}"  #"uniprot_data/seq_{index}"
    params:
        memory="1"
    threads:
        1
    run:
        """
        # create output directory
        #os.mkdir("uniprot_data")
        
        # load UPIs from file
        with open(input["upi_file"], "r") as input_handle:
            upis = [line.strip() for line in input_handle.readlines()]    
        upis_str = " ".join(upis)
        subprocess.run(['touch','upis_str_made'])
        # map the UPIs to Uniprot accessions
        params = {
        'from': 'UPARC',
        'to': 'ACC',
        'format': 'tab',
        'query': upis_str
        }

        data = urllib.parse.urlencode(params)
        data = data.encode('utf-8')
        req = urllib.request.Request(url, data)
        with urllib.request.urlopen(req) as f:
            response = f.read()
        mapping = response.decode('utf-8')

        accessions = [line.split('\t') for line in mapping.split('\n')]
        accessions = [id_entry[1] for id_entry in accessions if len(id_entry) == 2][1:] # skipping first elements since it contains header
        subprocess.run(['touch','accessions_made']
        # retrive the entries in format: id	organism	sequence
        url = 'uniprot.org/uniprot?format=tab&columns=id,organism,sequence&query=accession%3A' + accessions[0]

	for entry in accessions[1:]:
            url += '+OR+accession%3A' + entry

        subprocess.run(['wget','-O',output["uniprot_data"],url]
        """

def aggregate_uniprot(wildcards):
    checkpoints_output = checkpoints.split_UPIs.get(**wildcards).output[0]
    indeces = glob_wildcards(os.path.join(checkpoints_output, "upi_{index}")).index
    completed = expand("seq_{index}", index=indeces)
    return completed

rule merge_results:
    input:
        aggregate_uniprot
    output:
        "output.txt"
    log:
        "logs/merge_results.log"
    params:
        memory="1"
    threads:
        1
    shell:
        """
        cat {input} > {output}
        """  

 

# create desired output: sequence ID; AA sequence; species name; TPS class
#rule:
#input:
#params:
